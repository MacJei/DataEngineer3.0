divolte {
  global {

    server {
      host = 0.0.0.0
      port = 8290
    }

    kafka {
      // Enable Kafka flushing
      enabled = true
      // The properties under the producer key in this
      // configuration are used to create a Properties object
      // which is passed to Kafka as is. At the very least,
      // configure the broker list here. For more options
      // that can be passed to a Kafka producer, see this link:
      // https://kafka.apache.org/documentation.html#producerconfigs
      producer = {
        bootstrap.servers = "de3-node1.europe-west1-b.c.dataengineer-218321.internal:6667"
      }
    }
  }
  sinks {
    // The name of the sink. ("It's referred to by the mapping.")
    kafka {
      type = kafka
      // This is the name of the topic that data will be produced on
      topic = ilya.kruchinin
    }
  }
  sources {
    // Once we specify a source, we need to specify all of them.
    // Here's the definition for the browser source we've been using until now.
    browser = {
      type = browser
    }
    // Here's the low-level JSON source we're adding.
    json = {
      type = json
      event_path = /json
    }
  }
  mappings {
    my_mapping = {
      schema_file = "/home/kruchininilya77/divolte-collector-0.9.0/conf/MyEventRecord.avsc"
      mapping_script_file = "/home/kruchininilya77/divolte-collector-0.9.0/conf/mapping.groovy"
      sources = [browser, json]
      sinks = [kafka]
    }
  }
}